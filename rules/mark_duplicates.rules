# uses snakemake wrapper repository, https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/picard/markduplicates.html
# Runs out of java heap space if using miniconda default.
# To correct, add desired memory to jvm_mem_opts in the picard shell wrapper:
# miniconda3/envs/potato/share/picard-2.14.1-0/picard 
# Edit the line jmp_mem_opts=""
# I doubled the heap space from the default: -Xms512m -Xmx1g. This seemed to work fine.

# Picard memory update 16 Feb 2018: 2G throws OutOfMemory error when dedup aligned PL4 reads
# I increased heap space to 4G, i.e., -Xms512m -Xmx4g

# rule mark_duplicates:
#     input:
#         "data/aligned_reads/{sample}-{unit}-sorted.aln.bam"
#     output:
#         bam="data/dedup/{sample}-{unit}-dedup-sorted.aln.bam",
#         metrics="data/dedup/{sample}-{unit}-metrics.txt"
#     log:
#         "logs/picard/{sample}-{unit}.log"
#     params:
#         "REMOVE_DUPLICATES=true",
#         "TMP_DIR=./temp",
#         "ASSUME_SORT_ORDER=coordinate",
#         "MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000"
#     wrapper:
#         "0.19.3/bio/picard/markduplicates"

# Added wrapper-independent implementation to specify java heap space on command line
# for implementing on cluster.

rule mark_duplicates:
    input:
        "data/aligned_reads/{sample}-{unit}-sorted.aln.bam"
    output:
        bam="data/dedup/{sample}-{unit}-dedup-sorted.aln.bam",
        metrics="data/dedup/{sample}-{unit}-metrics.txt"
    log:
        "logs/picard/{sample}-{unit}.log"
    params:
        jarpath=config["params"]["mark_duplicates"]["jarpath"],
        java_heap=config["params"]["mark_duplicates"]["java_heap"],
        opt=config["params"]["mark_duplicates"]["opt"]
    shell:
        "java {params.java_heap} -jar {params.jarpath} MarkDuplicates INPUT={input} "
        "OUTPUT={output.bam} METRICS_FILE={output.metrics} {params.opt} 2> {log}"
